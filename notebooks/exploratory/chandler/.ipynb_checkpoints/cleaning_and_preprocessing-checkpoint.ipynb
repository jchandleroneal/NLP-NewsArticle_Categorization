{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\">\n",
    "    <ul class=\"toc-item\">\n",
    "    <li><span><a href=\"#Cleaning the Data\" data-toc-modified-id=\"Cleaning the Data\">\n",
    "        <span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Cleaning the Data</a></span>    \n",
    "    <ul class=\"toc-item\">\n",
    "        <li><span><a href=\"#Importing the Data\" data-toc-modified-id=\"Importing the Data-1.1\">\n",
    "            <span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Importing the Data</a></span></li></ul></li>\n",
    "        <li><span><a href=\"#Inspecting the data\" data-toc-modified-id=\"Inspecting the data\">\n",
    "            <span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Inspecting the data</a></span>        \n",
    "    <ul class=\"toc-item\">\n",
    "        <li><span><a href=\"#Activation-functions-(from-before)\" data-toc-modified-id=\"Activation-functions-(from-before)-2.1\">\n",
    "              <span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Activation functions (from before)</a></span>  \n",
    "    <ul class=\"toc-item\">\n",
    "        <li><span><a href=\"#Recall-what-an-activation-function-does\" data-toc-modified-id=\"Recall-what-an-activation-function-does-2.1.1\">\n",
    "              <span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Recall what an activation function does</a></span></li>\n",
    "        <li><span><a href=\"#Using-the-proper-activation\" data-toc-modified-id=\"Using-the-proper-activation-2.1.2\">\n",
    "              <span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Using the proper activation</a></span></li></ul></li>\n",
    "        <li><span><a href=\"#Random-Starts\" data-toc-modified-id=\"Random-Starts-2.2\">\n",
    "              <span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Random Starts</a></span></li>\n",
    "        <li><span><a href=\"#Momentum\" data-toc-modified-id=\"Momentum-2.3\">\n",
    "              <span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Momentum</a></span>           \n",
    "    <ul class=\"toc-item\">\n",
    "        <li><span><a href=\"#Solution?--Give-it-some-speed-😎\" data-toc-modified-id=\"Solution?--Give-it-some-speed-😎-2.3.1\">\n",
    "              <span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Solution?  Give it some speed 😎</a></span><ul class=\"toc-item\">\n",
    "        <li><span><a href=\"#Code-Implementation\" data-toc-modified-id=\"Code-Implementation-2.3.1.1\">\n",
    "              <span class=\"toc-item-num\">2.3.1.1&nbsp;&nbsp;</span>Code Implementation</a></span></li></ul></li></ul></li></ul></li>\n",
    "        <li><span><a href=\"#Make-it-Go-Faster-with-Optimizers!\" data-toc-modified-id=\"Make-it-Go-Faster-with-Optimizers!-3\">\n",
    "              <span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Make it Go Faster with Optimizers!</a></span>            \n",
    "    <ul class=\"toc-item\">\n",
    "        <li><span><a href=\"#Normalization-(Batch-Normalization)\" data-toc-modified-id=\"Normalization-(Batch-Normalization)-3.1\">\n",
    "            <span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Normalization (Batch Normalization)</a></span></li>\n",
    "        <li><span><a href=\"#Stochastic-Gradient-Descent\" data-toc-modified-id=\"Stochastic-Gradient-Descent-3.2\">\n",
    "            <span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Stochastic Gradient Descent</a></span><ul class=\"toc-item\">\n",
    "        <li><span><a href=\"#Steps\" data-toc-modified-id=\"Steps-3.2.1\">\n",
    "            <span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Steps</a></span></li></ul></li>\n",
    "        <li><span><a href=\"#AdaGrad-&amp;-RMSProp\" data-toc-modified-id=\"AdaGrad-&amp;-RMSProp-3.3\">\n",
    "            <span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>AdaGrad &amp; RMSProp</a></span>                        \n",
    "    <ul class=\"toc-item\">\n",
    "        <li><span><a href=\"#Code-Example\" data-toc-modified-id=\"Code-Example-3.3.1\">\n",
    "            <span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Code Example</a></span></li></ul></li>\n",
    "        <li><span><a href=\"#Adam-(Adaptivr-Moment-Estimation)-Optimization-and-Other-Variants\" data-toc-modified-id=\"Adam-(Adaptivr-Moment-\n",
    "                          Estimation)-Optimization-and-Other-Variants-3.4\">\n",
    "            <span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Adam (Adaptivr Moment Estimation) Optimization and Other Variants</a></span></li>          <li><span><a href=\"#Learning-Rate-Decay\" data-toc-modified-id=\"Learning-Rate-Decay-3.5\">\n",
    "            <span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Learning Rate Decay</a></span><ul class=\"toc-item\">\n",
    "        <li><span><a href=\"#Solution?\" data-toc-modified-id=\"Solution?-3.5.1\">\n",
    "            <span class=\"toc-item-num\">3.5.1&nbsp;&nbsp;</span>Solution?</a></span></li>\n",
    "        <li><span><a href=\"#Code-Example\" data-toc-modified-id=\"Code-Example-3.5.2\">\n",
    "            <span class=\"toc-item-num\">3.5.2&nbsp;&nbsp;</span>Code Example</a></span></li>\n",
    "</ul>\n",
    "</li>\n",
    "        \n",
    "</ul>\n",
    "</li>\n",
    "        \n",
    "</ul>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-6e00ddf9d3a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd \n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "plt.style.use('fivethirtyeight')\n",
    "import nltk # importing Natural Landuage Processing Toolit\n",
    "from nltk.corpus import stopwords #importing stop words to remove non-necissary words\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import re \n",
    "import nltk\n",
    "import string\n",
    "\n",
    "\n",
    "raw_data = pd.read_json('../../../data/data.json', lines=True)\n",
    "\n",
    "raw_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Inspecting the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200853 entries, 0 to 200852\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count   Dtype         \n",
      "---  ------             --------------   -----         \n",
      " 0   category           200853 non-null  object        \n",
      " 1   headline           200853 non-null  object        \n",
      " 2   authors            200853 non-null  object        \n",
      " 3   link               200853 non-null  object        \n",
      " 4   short_description  200853 non-null  object        \n",
      " 5   date               200853 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(5)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#inspecting the data types - Noticed that they're all objects \n",
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category             0\n",
       "headline             0\n",
       "authors              0\n",
       "link                 0\n",
       "short_description    0\n",
       "date                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking For Null Values\n",
    "raw_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIME</td>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "      <td>Melissa Jeltsen</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/texas-ama...</td>\n",
       "      <td>She left her husband. He killed their children...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>Andy McDonald</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
       "      <td>Of course it has a song.</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n",
       "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/jim-carre...</td>\n",
       "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/julianna-...</td>\n",
       "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                           headline  \\\n",
       "0          CRIME  There Were 2 Mass Shootings In Texas Last Week...   \n",
       "1  ENTERTAINMENT  Will Smith Joins Diplo And Nicky Jam For The 2...   \n",
       "2  ENTERTAINMENT    Hugh Grant Marries For The First Time At Age 57   \n",
       "3  ENTERTAINMENT  Jim Carrey Blasts 'Castrato' Adam Schiff And D...   \n",
       "4  ENTERTAINMENT  Julianna Margulies Uses Donald Trump Poop Bags...   \n",
       "\n",
       "           authors                                               link  \\\n",
       "0  Melissa Jeltsen  https://www.huffingtonpost.com/entry/texas-ama...   \n",
       "1    Andy McDonald  https://www.huffingtonpost.com/entry/will-smit...   \n",
       "2       Ron Dicker  https://www.huffingtonpost.com/entry/hugh-gran...   \n",
       "3       Ron Dicker  https://www.huffingtonpost.com/entry/jim-carre...   \n",
       "4       Ron Dicker  https://www.huffingtonpost.com/entry/julianna-...   \n",
       "\n",
       "                                   short_description       date  \n",
       "0  She left her husband. He killed their children... 2018-05-26  \n",
       "1                           Of course it has a song. 2018-05-26  \n",
       "2  The actor and his longtime girlfriend Anna Ebe... 2018-05-26  \n",
       "3  The actor gives Dems an ass-kicking for not fi... 2018-05-26  \n",
       "4  The \"Dietland\" actress said using the bags is ... 2018-05-26  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reassigning dataframe to df to uphold the original structure of the data - used for later references.\n",
    "df = raw_data.copy()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Data for Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Punctuation and cleaning rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Short Description Feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         She left her husband. He killed their children...\n",
       "1                                  Of course it has a song.\n",
       "2         The actor and his longtime girlfriend Anna Ebe...\n",
       "3         The actor gives Dems an ass-kicking for not fi...\n",
       "4         The \"Dietland\" actress said using the bags is ...\n",
       "                                ...                        \n",
       "200848    Verizon Wireless and AT&T are already promotin...\n",
       "200849    Afterward, Azarenka, more effusive with the pr...\n",
       "200850    Leading up to Super Bowl XLVI, the most talked...\n",
       "200851    CORRECTION: An earlier version of this story i...\n",
       "200852    The five-time all-star center tore into his te...\n",
       "Name: short_description, Length: 200853, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.short_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         There Were 2 Mass Shootings In Texas Last Week...\n",
       "1         Will Smith Joins Diplo And Nicky Jam For The 2...\n",
       "2           Hugh Grant Marries For The First Time At Age 57\n",
       "3         Jim Carrey Blasts 'Castrato' Adam Schiff And D...\n",
       "4         Julianna Margulies Uses Donald Trump Poop Bags...\n",
       "                                ...                        \n",
       "200848    RIM CEO Thorsten Heins' 'Significant' Plans Fo...\n",
       "200849    Maria Sharapova Stunned By Victoria Azarenka I...\n",
       "200850    Giants Over Patriots, Jets Over Colts Among  M...\n",
       "200851    Aldon Smith Arrested: 49ers Linebacker Busted ...\n",
       "200852    Dwight Howard Rips Teammates After Magic Loss ...\n",
       "Name: headline, Length: 200853, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.headline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing Casing and punctuaton**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-b94dc7d217fb>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['short_description'] = df['short_description'].str.lower().str.replace('[^\\w\\s]','')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    she left her husband he killed their children ...\n",
      "1                              of course it has a song\n",
      "Name: short_description, dtype: object\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-b94dc7d217fb>:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['headline'] = df['headline'].str.lower().str.replace('[^\\w\\s]','')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0    there were 2 mass shootings in texas last week...\n",
      "1    will smith joins diplo and nicky jam for the 2...\n",
      "Name: headline, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Removing punctuation. It helps us reduce the size of the data \n",
    "df['short_description'] = df['short_description'].str.lower().str.replace('[^\\w\\s]','')\n",
    "print(df['short_description'].head(2))\n",
    "\n",
    "print('\\n============================================================')\n",
    "\n",
    "df['headline'] = df['headline'].str.lower().str.replace('[^\\w\\s]','')\n",
    "print('\\n', df['headline'].head(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merging Description and Headline together**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* checking lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.short_description[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.headline[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merging\n",
    "df['head_description'] = df.headline + ' ' + df.short_description\n",
    "len(df.head_description[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Removing Non-Contributional Words from the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jordan\n",
      "[nltk_data]     Johnson\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#downloading stopwords to use\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "#inspecting stop words \n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head_description</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>there were 2 mass shootings in texas last week...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>will smith joins diplo and nicky jam for the 2...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hugh grant marries for the first time at age 5...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jim carrey blasts castrato adam schiff and dem...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>julianna margulies uses donald trump poop bags...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    head_description  stopwords\n",
       "0  there were 2 mass shootings in texas last week...         12\n",
       "1  will smith joins diplo and nicky jam for the 2...          8\n",
       "2  hugh grant marries for the first time at age 5...          9\n",
       "3  jim carrey blasts castrato adam schiff and dem...          7\n",
       "4  julianna margulies uses donald trump poop bags...          8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many stop words do we have? \n",
    "df['stopwords'] = df['head_description'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "df[['head_description','stopwords']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>date</th>\n",
       "      <th>head_description</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIME</td>\n",
       "      <td>there were 2 mass shootings in texas last week...</td>\n",
       "      <td>Melissa Jeltsen</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/texas-ama...</td>\n",
       "      <td>she left her husband he killed their children ...</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>there were 2 mass shootings in texas last week...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>will smith joins diplo and nicky jam for the 2...</td>\n",
       "      <td>Andy McDonald</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
       "      <td>of course it has a song</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>will smith joins diplo and nicky jam for the 2...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                           headline  \\\n",
       "0          CRIME  there were 2 mass shootings in texas last week...   \n",
       "1  ENTERTAINMENT  will smith joins diplo and nicky jam for the 2...   \n",
       "\n",
       "           authors                                               link  \\\n",
       "0  Melissa Jeltsen  https://www.huffingtonpost.com/entry/texas-ama...   \n",
       "1    Andy McDonald  https://www.huffingtonpost.com/entry/will-smit...   \n",
       "\n",
       "                                   short_description       date  \\\n",
       "0  she left her husband he killed their children ... 2018-05-26   \n",
       "1                            of course it has a song 2018-05-26   \n",
       "\n",
       "                                    head_description  stopwords  \n",
       "0  there were 2 mass shootings in texas last week...         12  \n",
       "1  will smith joins diplo and nicky jam for the 2...          8  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspecting stop words column to identify the number of unnecissary words within each column\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing Stop Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing stopwords \n",
    "df['clean_head_description'] = df['head_description'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2 mass shootings texas last week 1 tv left hus...\n",
       "1    smith joins diplo nicky jam 2018 world cups of...\n",
       "2    hugh grant marries first time age 57 actor lon...\n",
       "3    jim carrey blasts castrato adam schiff democra...\n",
       "4    julianna margulies uses donald trump poop bags...\n",
       "Name: clean_head_description, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_head_description'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the Text to Up Sentences Into a List of Words:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **splitting a phrase, sentence, paragraph, or an entire text document into smaller units, such as individual words or terms. Each of these smaller units are called tokens.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmitizing the data to reduce repitition by removing the affixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiating a lemmatizer\n",
    "lemma = WordNetLemmatizer() #instantiate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing affixes from all words\n",
    "def lemm_words(data):\n",
    "    tokens = word_tokenize(data)   #Tokenizing data \n",
    "    lemmed_tokens = [lemma.lemmatize(word) for word in tokens]   #lemmatizing data\n",
    "    return ' '.join(lemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmed = df.head_description.apply(lemm_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = lemmed                              #there were 2 mass shooting in texas last week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing series into a list of lists \n",
    "df['unique_word'] = l.str.split(' ')   # [there, were, 2, mass, shooting, in, texas, la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating a Bag of Words for Vectorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list containing all words \n",
    "\n",
    "unique_lemmed_list = []                #the  (appears ->)  261830\n",
    "for x in df['unique_word']:  \n",
    "    unique_lemmed_list += x  # append elements of lists to full list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Removing Single Characters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5855301"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspecting the original number of words\n",
    "len(unique_lemmed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looping through and adding words > len(1) to a new list \n",
    "full_words = [] # creating quotes \n",
    "index = 0\n",
    "for words in unique_lemmed_list: \n",
    "    if len(words) > 1:\n",
    "        full_words.append(words)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5621546"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the NEW number of words after removal\n",
    "len(full_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Changing New Bag of Words into a Series for TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the           261830\n",
       "to            163957\n",
       "of            128119\n",
       "and           119623\n",
       "in             95541\n",
       "               ...  \n",
       "saaang             1\n",
       "charrière          1\n",
       "sixpackabs         1\n",
       "0447               1\n",
       "fallish            1\n",
       "Length: 102078, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_value_counts = pd.Series(full_words).value_counts()\n",
    "word_value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>261830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "      <td>163957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>128119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>119623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in</td>\n",
       "      <td>95541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word   count\n",
       "0  the  261830\n",
       "1   to  163957\n",
       "2   of  128119\n",
       "3  and  119623\n",
       "4   in   95541"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot = pd.DataFrame(data = word_value_counts).reset_index()\n",
    "plot.columns = ['word','count']\n",
    "plot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' objects are mutable, thus they cannot be hashed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-644705c9c995>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m plot.plot.barh(x='word', y= plot.count\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                       \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36mbarh\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m   1197\u001b[0m         \u001b[0mother\u001b[0m \u001b[0maxis\u001b[0m \u001b[0mrepresents\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmeasured\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m         \"\"\"\n\u001b[1;32m-> 1199\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"barh\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    940\u001b[0m                 \u001b[1;31m# don't overwrite\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 941\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    942\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    943\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2987\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2988\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2989\u001b[1;33m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2990\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2991\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36mapply_if_callable\u001b[1;34m(maybe_callable, obj, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m     \"\"\"\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mcount\u001b[1;34m(self, axis, level, numeric_only)\u001b[0m\n\u001b[0;32m   8703\u001b[0m         \u001b[0mMyla\u001b[0m      \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8704\u001b[0m         \"\"\"\n\u001b[1;32m-> 8705\u001b[1;33m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8706\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8707\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_axis_number\u001b[1;34m(cls, axis)\u001b[0m\n\u001b[0;32m    458\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAxis\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_AXIS_TO_AXIS_NUMBER\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"No axis named {axis} for object type {cls.__name__}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1783\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1784\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1785\u001b[1;33m         raise TypeError(\n\u001b[0m\u001b[0;32m   1786\u001b[0m             \u001b[1;34mf\"{repr(type(self).__name__)} objects are mutable, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1787\u001b[0m             \u001b[1;34mf\"thus they cannot be hashed\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DataFrame' objects are mutable, thus they cannot be hashed"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1296 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word = plot.word\n",
    "count = plot.count\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,18))\n",
    "\n",
    "plot.plot.barh(x='word', y= plot.count\n",
    ",\n",
    "                      ax=ax,\n",
    "                      color=\"purple\")\n",
    "\n",
    "# plot.word.value_counts()[:20].sort_index(ascending=False).plot(kind='barh')\n",
    "\n",
    "\n",
    "# ax.set_title(\"Common Words Found in DS Job Descriptions(Without Stop Words)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **TF - IDF**\n",
    "\n",
    "**Term Frequency — Inverse Document Frequency** - Derermining word importance to documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    [will, smith, join, diplo, and, nicky, jam, fo...\n",
       "2    [hugh, grant, marries, for, the, first, time, ...\n",
       "3    [jim, carrey, blast, castrato, adam, schiff, a...\n",
       "4    [julianna, margulies, us, donald, trump, poop,...\n",
       "5    [morgan, freeman, devastated, that, sexual, ha...\n",
       "6    [donald, trump, is, lovin, new, mcdonalds, jin...\n",
       "7    [what, to, watch, on, amazon, prime, thats, ne...\n",
       "Name: head_description, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspecting lemmatized words \n",
    "l[1:8].str.split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Vectorizing the (title description + full description) column (converting it into numeric data).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a function to pass into the analyzer to clean the raw data \n",
    "    \n",
    "def clean_history(history):\n",
    "    history = \"\".join([word for word in history if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', history)\n",
    "    history = [wn.lemmatize(word) for word in tokens if word not in stopwords]\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returning Trigrams - Groups of Three Words\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer=lemm_words, ngram_range =(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = tfidf_vectorizer.fit_transform(df['head_description'])\n",
    "features = (tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Shape of tfidf : \n",
      " (200853, 172)\n",
      "\n",
      "\n",
      "Features : \n",
      " [' ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¹', 'º', '¼', '½', '¾', 'à', 'á', 'â', 'ã', 'ä', 'å', 'æ', 'ç', 'è', 'é', 'ê', 'ë', 'ì', 'í', 'î', 'ï', 'ñ', 'ò', 'ó', 'ô', 'ö', 'ø', 'ù', 'ú', 'û', 'ü', 'ý', 'ā', 'ć', 'č', 'ē', 'ė', 'ğ', 'ī', 'ł', 'ń', 'ō', 'œ', 'ś', 'ş', 'š', 'ū', 'ů', 'ű', 'ž', 'ǒ', 'ș', 'ə', 'ɛ', 'ɪ', 'ʻ', 'ʼ', 'ˈ', 'ˌ', 'ː', 'ά', 'έ', 'ί', 'α', 'γ', 'δ', 'ε', 'η', 'ι', 'κ', 'λ', 'μ', 'ν', 'ξ', 'ο', 'ρ', 'ς', 'σ', 'τ', 'υ', 'ω', 'ό', 'ύ', 'ώ', 'а', 'б', 'в', 'г', 'е', 'ж', 'з', 'и', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ы', 'ь', 'я', 'আ', 'ই', 'গ', 'ট', 'ভ', 'র', 'ল', 'স', 'ಠ', 'ᴥ', 'ᵒ', 'ᶅ', 'ᶘ', 'ạ', 'ấ', 'ầ', 'ễ', '②', 'ツ', '象', 'ﬁ', 'ﬂ', 'ﾨ', 'ﾩ', 'ﾫ', 'ﾴ', 'ￃ']\n",
      "\n",
      "\n",
      "X1 : \n",
      " [[0.66833775 0.         0.07769452 ... 0.         0.         0.        ]\n",
      " [0.67954942 0.11216167 0.10810236 ... 0.         0.         0.        ]\n",
      " [0.60803435 0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.65815691 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.56602127 0.06574247 0.12672629 ... 0.         0.         0.        ]\n",
      " [0.5483322  0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nShape of tfidf : \\n\", X_tfidf.shape)\n",
    "\n",
    "\n",
    "#printing out the features \n",
    "print(\"\\n\\nFeatures : \\n\", features)\n",
    "print(\"\\n\\nX1 : \\n\", X_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf_df = pd.DataFrame(X_tfidf.toarray(),columns=features)\n",
    "# X_tfidf_df.columns = X_tfidf.features\n",
    "# X_tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>②</th>\n",
       "      <th>ツ</th>\n",
       "      <th>象</th>\n",
       "      <th>ﬁ</th>\n",
       "      <th>ﬂ</th>\n",
       "      <th>ﾨ</th>\n",
       "      <th>ﾩ</th>\n",
       "      <th>ﾫ</th>\n",
       "      <th>ﾴ</th>\n",
       "      <th>ￃ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.668338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077695</td>\n",
       "      <td>0.085409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.679549</td>\n",
       "      <td>0.112162</td>\n",
       "      <td>0.108102</td>\n",
       "      <td>0.118837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.16265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.608034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111361</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.589118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.609229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200848</th>\n",
       "      <td>0.543538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200849</th>\n",
       "      <td>0.557213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200850</th>\n",
       "      <td>0.658157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200851</th>\n",
       "      <td>0.566021</td>\n",
       "      <td>0.065742</td>\n",
       "      <td>0.126726</td>\n",
       "      <td>0.069655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200852</th>\n",
       "      <td>0.548332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067478</td>\n",
       "      <td>0.082488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200853 rows × 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0         1         2         3         4         5  \\\n",
       "0       0.668338  0.000000  0.077695  0.085409  0.000000  0.000000  0.000000   \n",
       "1       0.679549  0.112162  0.108102  0.118837  0.000000  0.000000  0.000000   \n",
       "2       0.608034  0.000000  0.000000  0.000000  0.000000  0.000000  0.097348   \n",
       "3       0.589118  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4       0.609229  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "200848  0.543538  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "200849  0.557213  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "200850  0.658157  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "200851  0.566021  0.065742  0.126726  0.069655  0.000000  0.088233  0.000000   \n",
       "200852  0.548332  0.000000  0.000000  0.067478  0.082488  0.000000  0.000000   \n",
       "\n",
       "          6         7        8  ...    ②    ツ    象    ﬁ    ﬂ    ﾨ    ﾩ    ﾫ  \\\n",
       "0       0.0  0.000000  0.00000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1       0.0  0.000000  0.16265  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2       0.0  0.111361  0.00000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3       0.0  0.000000  0.00000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4       0.0  0.000000  0.00000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...     ...       ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "200848  0.0  0.000000  0.00000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "200849  0.0  0.000000  0.00000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "200850  0.0  0.000000  0.00000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "200851  0.0  0.000000  0.00000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "200852  0.0  0.000000  0.00000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "          ﾴ    ￃ  \n",
       "0       0.0  0.0  \n",
       "1       0.0  0.0  \n",
       "2       0.0  0.0  \n",
       "3       0.0  0.0  \n",
       "4       0.0  0.0  \n",
       "...     ...  ...  \n",
       "200848  0.0  0.0  \n",
       "200849  0.0  0.0  \n",
       "200850  0.0  0.0  \n",
       "200851  0.0  0.0  \n",
       "200852  0.0  0.0  \n",
       "\n",
       "[200853 rows x 172 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'WordListCorpusReader' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-970ac171f1a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtfidf_vect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclean_history\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngram_range\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf_vect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'head_description'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_vect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1848\u001b[0m         \"\"\"\n\u001b[0;32m   1849\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1850\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1851\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[0;32m   1204\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1115\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1116\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1117\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0manalyzer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-66490add113f>\u001b[0m in \u001b[0;36mclean_history\u001b[1;34m(history)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\W+'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mwn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-66490add113f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\W+'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mwn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: argument of type 'WordListCorpusReader' is not iterable"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer=clean_history, ngram_range =(2, 2))\n",
    "X_tfidf = tfidf_vect.fit_transform(df['head_description'])\n",
    "\n",
    "print(X_tfidf.shape)\n",
    "print(tfidf_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>date</th>\n",
       "      <th>head_description</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>clean_head_description</th>\n",
       "      <th>unique_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIME</td>\n",
       "      <td>there were 2 mass shootings in texas last week...</td>\n",
       "      <td>Melissa Jeltsen</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/texas-ama...</td>\n",
       "      <td>she left her husband he killed their children ...</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>there were 2 mass shootings in texas last week...</td>\n",
       "      <td>12</td>\n",
       "      <td>2 mass shootings texas last week 1 tv left hus...</td>\n",
       "      <td>[there, were, 2, mass, shooting, in, texas, la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>will smith joins diplo and nicky jam for the 2...</td>\n",
       "      <td>Andy McDonald</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
       "      <td>of course it has a song</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>will smith joins diplo and nicky jam for the 2...</td>\n",
       "      <td>8</td>\n",
       "      <td>smith joins diplo nicky jam 2018 world cups of...</td>\n",
       "      <td>[will, smith, join, diplo, and, nicky, jam, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>hugh grant marries for the first time at age 57</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n",
       "      <td>the actor and his longtime girlfriend anna ebe...</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>hugh grant marries for the first time at age 5...</td>\n",
       "      <td>9</td>\n",
       "      <td>hugh grant marries first time age 57 actor lon...</td>\n",
       "      <td>[hugh, grant, marries, for, the, first, time, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>jim carrey blasts castrato adam schiff and dem...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/jim-carre...</td>\n",
       "      <td>the actor gives dems an asskicking for not fig...</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>jim carrey blasts castrato adam schiff and dem...</td>\n",
       "      <td>7</td>\n",
       "      <td>jim carrey blasts castrato adam schiff democra...</td>\n",
       "      <td>[jim, carrey, blast, castrato, adam, schiff, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>julianna margulies uses donald trump poop bags...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/julianna-...</td>\n",
       "      <td>the dietland actress said using the bags is a ...</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>julianna margulies uses donald trump poop bags...</td>\n",
       "      <td>8</td>\n",
       "      <td>julianna margulies uses donald trump poop bags...</td>\n",
       "      <td>[julianna, margulies, us, donald, trump, poop,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200848</th>\n",
       "      <td>TECH</td>\n",
       "      <td>rim ceo thorsten heins significant plans for b...</td>\n",
       "      <td>Reuters, Reuters</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/rim-ceo-t...</td>\n",
       "      <td>verizon wireless and att are already promoting...</td>\n",
       "      <td>2012-01-28</td>\n",
       "      <td>rim ceo thorsten heins significant plans for b...</td>\n",
       "      <td>5</td>\n",
       "      <td>rim ceo thorsten heins significant plans black...</td>\n",
       "      <td>[rim, ceo, thorsten, heins, significant, plan,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200849</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>maria sharapova stunned by victoria azarenka i...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.huffingtonpost.com/entry/maria-sha...</td>\n",
       "      <td>afterward azarenka more effusive with the pres...</td>\n",
       "      <td>2012-01-28</td>\n",
       "      <td>maria sharapova stunned by victoria azarenka i...</td>\n",
       "      <td>10</td>\n",
       "      <td>maria sharapova stunned victoria azarenka aust...</td>\n",
       "      <td>[maria, sharapova, stunned, by, victoria, azar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200850</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>giants over patriots jets over colts among  mo...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.huffingtonpost.com/entry/super-bow...</td>\n",
       "      <td>leading up to super bowl xlvi the most talked ...</td>\n",
       "      <td>2012-01-28</td>\n",
       "      <td>giants over patriots jets over colts among  mo...</td>\n",
       "      <td>17</td>\n",
       "      <td>giants patriots jets colts among improbable su...</td>\n",
       "      <td>[giant, over, patriot, jet, over, colt, among,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200851</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>aldon smith arrested 49ers linebacker busted f...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.huffingtonpost.com/entry/aldon-smi...</td>\n",
       "      <td>correction an earlier version of this story in...</td>\n",
       "      <td>2012-01-28</td>\n",
       "      <td>aldon smith arrested 49ers linebacker busted f...</td>\n",
       "      <td>9</td>\n",
       "      <td>aldon smith arrested 49ers linebacker busted d...</td>\n",
       "      <td>[aldon, smith, arrested, 49ers, linebacker, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200852</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>dwight howard rips teammates after magic loss ...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.huffingtonpost.com/entry/dwight-ho...</td>\n",
       "      <td>the fivetime allstar center tore into his team...</td>\n",
       "      <td>2012-01-28</td>\n",
       "      <td>dwight howard rips teammates after magic loss ...</td>\n",
       "      <td>7</td>\n",
       "      <td>dwight howard rips teammates magic loss hornet...</td>\n",
       "      <td>[dwight, howard, rip, teammate, after, magic, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200853 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             category                                           headline  \\\n",
       "0               CRIME  there were 2 mass shootings in texas last week...   \n",
       "1       ENTERTAINMENT  will smith joins diplo and nicky jam for the 2...   \n",
       "2       ENTERTAINMENT    hugh grant marries for the first time at age 57   \n",
       "3       ENTERTAINMENT  jim carrey blasts castrato adam schiff and dem...   \n",
       "4       ENTERTAINMENT  julianna margulies uses donald trump poop bags...   \n",
       "...               ...                                                ...   \n",
       "200848           TECH  rim ceo thorsten heins significant plans for b...   \n",
       "200849         SPORTS  maria sharapova stunned by victoria azarenka i...   \n",
       "200850         SPORTS  giants over patriots jets over colts among  mo...   \n",
       "200851         SPORTS  aldon smith arrested 49ers linebacker busted f...   \n",
       "200852         SPORTS  dwight howard rips teammates after magic loss ...   \n",
       "\n",
       "                 authors                                               link  \\\n",
       "0        Melissa Jeltsen  https://www.huffingtonpost.com/entry/texas-ama...   \n",
       "1          Andy McDonald  https://www.huffingtonpost.com/entry/will-smit...   \n",
       "2             Ron Dicker  https://www.huffingtonpost.com/entry/hugh-gran...   \n",
       "3             Ron Dicker  https://www.huffingtonpost.com/entry/jim-carre...   \n",
       "4             Ron Dicker  https://www.huffingtonpost.com/entry/julianna-...   \n",
       "...                  ...                                                ...   \n",
       "200848  Reuters, Reuters  https://www.huffingtonpost.com/entry/rim-ceo-t...   \n",
       "200849                    https://www.huffingtonpost.com/entry/maria-sha...   \n",
       "200850                    https://www.huffingtonpost.com/entry/super-bow...   \n",
       "200851                    https://www.huffingtonpost.com/entry/aldon-smi...   \n",
       "200852                    https://www.huffingtonpost.com/entry/dwight-ho...   \n",
       "\n",
       "                                        short_description       date  \\\n",
       "0       she left her husband he killed their children ... 2018-05-26   \n",
       "1                                 of course it has a song 2018-05-26   \n",
       "2       the actor and his longtime girlfriend anna ebe... 2018-05-26   \n",
       "3       the actor gives dems an asskicking for not fig... 2018-05-26   \n",
       "4       the dietland actress said using the bags is a ... 2018-05-26   \n",
       "...                                                   ...        ...   \n",
       "200848  verizon wireless and att are already promoting... 2012-01-28   \n",
       "200849  afterward azarenka more effusive with the pres... 2012-01-28   \n",
       "200850  leading up to super bowl xlvi the most talked ... 2012-01-28   \n",
       "200851  correction an earlier version of this story in... 2012-01-28   \n",
       "200852  the fivetime allstar center tore into his team... 2012-01-28   \n",
       "\n",
       "                                         head_description  stopwords  \\\n",
       "0       there were 2 mass shootings in texas last week...         12   \n",
       "1       will smith joins diplo and nicky jam for the 2...          8   \n",
       "2       hugh grant marries for the first time at age 5...          9   \n",
       "3       jim carrey blasts castrato adam schiff and dem...          7   \n",
       "4       julianna margulies uses donald trump poop bags...          8   \n",
       "...                                                   ...        ...   \n",
       "200848  rim ceo thorsten heins significant plans for b...          5   \n",
       "200849  maria sharapova stunned by victoria azarenka i...         10   \n",
       "200850  giants over patriots jets over colts among  mo...         17   \n",
       "200851  aldon smith arrested 49ers linebacker busted f...          9   \n",
       "200852  dwight howard rips teammates after magic loss ...          7   \n",
       "\n",
       "                                   clean_head_description  \\\n",
       "0       2 mass shootings texas last week 1 tv left hus...   \n",
       "1       smith joins diplo nicky jam 2018 world cups of...   \n",
       "2       hugh grant marries first time age 57 actor lon...   \n",
       "3       jim carrey blasts castrato adam schiff democra...   \n",
       "4       julianna margulies uses donald trump poop bags...   \n",
       "...                                                   ...   \n",
       "200848  rim ceo thorsten heins significant plans black...   \n",
       "200849  maria sharapova stunned victoria azarenka aust...   \n",
       "200850  giants patriots jets colts among improbable su...   \n",
       "200851  aldon smith arrested 49ers linebacker busted d...   \n",
       "200852  dwight howard rips teammates magic loss hornet...   \n",
       "\n",
       "                                              unique_word  \n",
       "0       [there, were, 2, mass, shooting, in, texas, la...  \n",
       "1       [will, smith, join, diplo, and, nicky, jam, fo...  \n",
       "2       [hugh, grant, marries, for, the, first, time, ...  \n",
       "3       [jim, carrey, blast, castrato, adam, schiff, a...  \n",
       "4       [julianna, margulies, us, donald, trump, poop,...  \n",
       "...                                                   ...  \n",
       "200848  [rim, ceo, thorsten, heins, significant, plan,...  \n",
       "200849  [maria, sharapova, stunned, by, victoria, azar...  \n",
       "200850  [giant, over, patriot, jet, over, colt, among,...  \n",
       "200851  [aldon, smith, arrested, 49ers, linebacker, bu...  \n",
       "200852  [dwight, howard, rip, teammate, after, magic, ...  \n",
       "\n",
       "[200853 rows x 10 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set X and Y for train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = X_tfidf_df\n",
    "y = df.category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling_function(model, X_train, y_train, X_val, y_val):\n",
    "\n",
    "    # fit model on training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions on training and validation data\n",
    "    train_preds = model.predict(X_train)\n",
    "    val_preds = model.predict(X_val)\n",
    "\n",
    "    # Print accuracy score\n",
    "    print('Training accuracy: ', f1_score_score(y_train, train_preds))\n",
    "    print('Validation accuracy: ', f1_score(y_val, val_preds))\n",
    "\n",
    "    # return fitted model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_tr, X_test, y_tr, y_test = train_test_split(X, y, test_size=20, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_tr, y_tr, test_size=.20, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-3ffe2a17c527>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodeling_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_res' is not defined"
     ]
    }
   ],
   "source": [
    "dt = modeling_function(dt, X_train_res, y_train_res, X_val_df, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
